- Different implementations of BLAS - taken into account
- Cost of BLAS functions initially done by going through the Fortran code
- Wondered about the cost of rand(), sqrt... - count them as 1 (happen rarely)
- Wondered if we should count comparison as an op - no (happens rarely)
- Making BLAS single threaded
- OpenBLAS first! - if we have time, we can do a little analysis on different BLAS impls and their performance
- For benchmarking
	- used seconds so we can run code in all languages
	- same number of iterations
	- same init method - random
	- one machine, but different than the one we ran our code on regularly (Viktor's computer)
	- R is 3
	- ran 3 times and averaged
	- ran impls up to the sizes it could handle
- note the R value for each plot
- plots:
	- performance_bs1_3D
	- performance_bs2_3D
	- mkl_vs_openBLAS
	(previous 3 are very cool plots and should be used, but need to be 	improved beforehand)

- Blas performance:
	- MMM performance drastically decreases when the matrix size is such that the common dimension is small. The MMM is in fact closer to a matrix vector
	  multiplication. In tests when multiplying matrices (400 x 3) (3 x 400) the performance drops from 12 f/c to 2 f/c. This is expected because the computation
	  now basically have a constant operational intensity.


- Optimizations:
*Optimization 0:
	- everything was put into a single file
	- functions were marked as inline
	- removed struct, now just using double*
	- removed function calls for allocation and deallocation
	- calculation of the norm of V is now done only once
	- matrix needed to calculate error (approx) is allocated only once
	- removed call for calculating the norm - now done in place
	- in the error function, two loops over the approx matrix were 	replaced with one + scalar replacement added and number of 	accesses to memory reduced by 1/3 per function call
	- error function now takes 1 / norm of V as a parameter so a div 	was replaced with a mul
	- dimensions of all matrices calculated only once and reused
	- double loops over matrices replaced with a single loop going 	sequentially over all elements (index calc simplified)
	- 1 / RAND_MAX was precalculated so all divisions during init are 	now multiplications

*Optimization 1:
	- simplified index calculations by using the methods of code motion and strength reduction in MM functions

*Optimization 2:
	- introduced blocking for cache in the MM functions (with care for simplified index calcs)

*Optimization 3:
	- Optimized the transpose function by introducing blocking and simplified index calcs

*Alg_opt_1:
	- We tried reusing matrix W in the computation of Hn+1 computing WtW and WtV in the same loop.
	  Matrix W and V are transposed to improve cache locality. The obtained performance with 
	  (m,n,r) = (200, 200, 5) is 0.68.

*Optimizations 21:
	- Loop unrolling for norm calculation to optimize error function
		- No improve (as expected since I was opitimizing lower terms in the cost)

*Optimization 22:
	- FAIL, the goal was to apply an optimization similar to
	  opt 6 on alg opt 2. We believe it might not be applicable.

*Optimization 23:
	- blocking for cache and using BLAS for inner multiplitcation
	- some transpose can be avoided but we tested and the transpose is	
	  time is negligible
	- performance highly depends on the rank (the higher the better) to	
	  use blas the most
	- despite blocking using V_col still gives an improvement (2.57 to 2.66 in the tests)

*Optimization 24:
	- the basic optimizations made in opt1 were transfered on baseline2 
	  as well. Loop unrolling for the norm is also used.

*Optimization 31:
	- Introduced register blocking in the MM functions
	- Degrades performance significantly
	- We can test a bit with different block sizes

*Optimization 32:
	- Introduced inner-most loop unrolling in the blocked version of MMs and transpose
	- Loop unrolling in the transpose function (factor 16) improves the runtime a bit
	- Loop unrolling in the MMs (factor 4) degrades performance a bit

*Optimization 33:
	- Intoduces an algorithmic change
	- H(n+1) is computed in a blockwise manner and the computed block is used instantly in the multiplications needed to calculate W(n+1)
	- All multiplications were done optimally with blocking and simplified index calculations and scalar replacement
	- Blocks of H are rectangular which allows for flexibility and can lead to performance benefits when the right block sizes are chosen

*Optimization 34:
	- On top of the algorithmic change from Optimization 33
	- Multiple block multiplications are merged into one triple-loops
	- Performance is the same (a bit worse runtime)	
	- Probably has to do with the fact that I reduced computation so the memory-bound nature was even more visible

*Optimization 35:
	- Intoduces an algorithmic change
	- W(n+1) is computed in a blockwise manner and the computed block is used instantly in the multiplications needed to calculate H(n+2)
	- All multiplications were done optimally with blocking and simplified index calculations and scalar replacement
	- Since this optimization plays accross the iteration border, we precalculate H1 before we go into the loop, then calculate W(n+1) and H(n+2) in the loop body. But the error test is still done on top of W(n+1), H(n+1)
	- Blocks of W are rectangular which allows for flexibility and can lead to performance benefits when the right block sizes are chosen

*Optimization 36:
	- On top of the algorithmic change from Optimization 34
	- Multiple block multiplications are merged into one triple-loops
	- Performance is the same (a bit worse runtime)	
	- Probably has to do with the fact that I reduced computation so the memory-bound nature was even more visible

*Optimization 41: 
	- on top of opt 24
	- uses dsyrk and dsymm to exploit the fact that WtW HHt are symmetric matrices. Surprisingly, no runtime improvement with 
	  respect to opt 24. 

*Optimization 42:
	- matrix multiplication is blocked 16x16, and has clean up loops for generalization
	- -mfma set in the compiler flags as they were not used (we chacked assembly)
	- kernel multiplication 16x16 is unrolled 2 times on the i loop and 4 on the j to have a total of 8 
	  independent computation
	- better ILP.

*Optimization 43:
	- vectorized mmul, rmul not vectorized, this is an intermediate optimization (don't plot)

*Optimization 44:
	- vectorized mmul used in the nmf, clean up loop not optimized were adding significant overhead

*Optimization 45:
	- optimized most importand clean up loops, the overhead is still significant

*Optimization 46:
	- because we noted that in terms of cycles adding a border up to 16 doubles to the matrices was not relevant
	  we pad the matrices to be multiple of the block size (16)
	- on top of opt 45 matrix multiplication
	- padds all the matrices s.t. m, n, r are now multiple of the block size. In this way it is possible to remove the cleanup loops
	- There's a single matrix mul and all the matrices are transposed when necessary

*Optimization 47:
	- uses vectorized error

*Optimization 37:
	- Version of 47 that uses non-aligned allocation and load and stores
	- For the sake of performance comparison
	- Introduces optimised version of transpose - vectorized and generalized for any input size
	- (The optimised transpose is now also in 47 so we need to take taht into account)

*Optimization 51:
	- Blending the improvements on MMs and transpose with the algorithmic opt reusing H
	- Uses the base from opt_47, the transpose from opt_37 and the algorithmic restructuring from opt_34 (opt_33 is commented, the difference is wether or not we merge multiple triple-loops into 1)
	- The interleaving of loops makes this version non general, it works with input sizes that are multiplies of 16
	- The knowledge from opt_47 MM is used in all multiplications on blocks
	- Since the only optimal MM is the one where no matrix is transposed, we need to pre-transpose the current calculated block
	- The element-wise division is also blocked
	- Very surprisingly and very sadly this yields no improvement, it even carries a bit of a downgrade 

*Optimization 53:
	- Blending the improvements on MMs and transpose with the algorithmic opt reusing W
	- Uses the base from opt_47, the transpose from opt_37 and the algorithmic restructuring from opt_35
- The knowledge from opt_47 MM is used in all multiplications on blocks
	- Since the only optimal MM is the one where no matrix is transposed, we need to pre-transpose the current calculated block
	- The element-wise division inside the block is also vectorized
	- Calculation of H was moved to reduce the number of memcopy calls

*Optimization 54:
	- On top of opt_51
	- Generalised implementation that works with arbitrary rank input
	- There is no interleaving of triple loops in order to achieve generality

*Optimization 48:
	- builds on top of 47
	- interlieves computation WtW and WtV / HHt and VVt
	- removes unnecessary memset and uses a buffer for intermediate result in blocked computation
	- vectorized transpose and error


*Optimization 60:
	- builds on top of 47
	- introduces a change in the error calculation
	- instead of computing the entire W*H and storing it in V_reconstructed and then reading it from there to compute the norm and the error, we work on a block of W*H as soon as it's computed and aggregate the error across it
	- the computation is fully vectorized
	- this approach reduces the number of reads of a matrix of the size m x n by half in the error function

*Optimization 61:
	- Introduces the novel way of calculating the error from 60 to the algorithmic improvement from 53
	- The optimization that performs the best
